{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55119fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import requests_cache\n",
    "import openmeteo_requests\n",
    "from retry_requests import retry\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Weather cache directory\n",
    "WEATHER_CACHE_DIR = Path(\"data/weather_cache\")\n",
    "WEATHER_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "START_DATE = \"2020-01-01\"\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdfee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_locations(event_df: pd.DataFrame) -> list[tuple]:\n",
    "    \"\"\"\n",
    "    Returns list of unique (lat, lon) pairs.\n",
    "    Filters out missing or invalid coordinates.\n",
    "    \"\"\"\n",
    "    coords = (\n",
    "        event_df[[\"latitude\", \"longitude\"]]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .itertuples(index=False, name=None)\n",
    "    )\n",
    "    return list(coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13caf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_for_location(lat: float, lon: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fetch historical hourly + daily weather for a single location.\n",
    "    \"\"\"\n",
    "\n",
    "    console.print(\n",
    "        Panel(\n",
    "            f\"[bold cyan]Fetching Weather for Location[/bold cyan]\\nLat={lat:.3f}, Lon={lon:.3f}\",\n",
    "            border_style=\"cyan\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cache_session = requests_cache.CachedSession(\".weather_cache\", expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.3)\n",
    "    client = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": START_DATE,\n",
    "        \"end_date\": END_DATE,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"precipitation\",\n",
    "            \"rain\",\n",
    "            \"apparent_temperature\",\n",
    "            \"weather_code\",\n",
    "            \"is_day\",\n",
    "        ],\n",
    "        \"daily\": [\n",
    "            \"sunrise\",\n",
    "            \"daylight_duration\",\n",
    "            \"sunshine_duration\",\n",
    "            \"precipitation_hours\",\n",
    "            \"rain_sum\",\n",
    "            \"temperature_2m_mean\",\n",
    "            \"weather_code\",\n",
    "        ],\n",
    "        \"timezone\": \"America/New_York\",\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "    }\n",
    "\n",
    "    responses = client.weather_api(url, params=params)\n",
    "    response = responses[0]\n",
    "\n",
    "    # -------- HOURLY DATA --------\n",
    "    hourly = response.Hourly()\n",
    "    hourly_df = pd.DataFrame({\n",
    "        \"datetime\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        ),\n",
    "        \"temp_f\": hourly.Variables(0).ValuesAsNumpy(),\n",
    "        \"precip_in\": hourly.Variables(1).ValuesAsNumpy(),\n",
    "        \"rain_in\": hourly.Variables(2).ValuesAsNumpy(),\n",
    "        \"apparent_temp_f\": hourly.Variables(3).ValuesAsNumpy(),\n",
    "        \"weather_code_hourly\": hourly.Variables(4).ValuesAsNumpy(),\n",
    "        \"is_daylight\": hourly.Variables(5).ValuesAsNumpy().astype(int),\n",
    "    })\n",
    "\n",
    "    hourly_df[\"datetime\"] = hourly_df[\"datetime\"].dt.tz_convert(\"America/New_York\").dt.tz_localize(None)\n",
    "\n",
    "    # -------- DAILY DATA --------\n",
    "    daily = response.Daily()\n",
    "    daily_df = pd.DataFrame({\n",
    "        \"date\": pd.date_range(\n",
    "            start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        ),\n",
    "        \"sunrise\": daily.Variables(0).ValuesInt64AsNumpy(),\n",
    "        \"daylight_duration_sec\": daily.Variables(1).ValuesAsNumpy(),\n",
    "        \"sunshine_duration_sec\": daily.Variables(2).ValuesAsNumpy(),\n",
    "        \"precip_hours\": daily.Variables(3).ValuesAsNumpy(),\n",
    "        \"rain_sum_in\": daily.Variables(4).ValuesAsNumpy(),\n",
    "        \"temp_mean_f\": daily.Variables(5).ValuesAsNumpy(),\n",
    "        \"weather_code_daily\": daily.Variables(6).ValuesAsNumpy(),\n",
    "    })\n",
    "\n",
    "    daily_df[\"date\"] = daily_df[\"date\"].dt.tz_convert(\"America/New_York\").dt.tz_localize(None).dt.date\n",
    "\n",
    "    return hourly_df, daily_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35274cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_fetch_weather(lat: float, lon: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    safe_lat = f\"{lat:.3f}\".replace(\".\", \"_\")\n",
    "    safe_lon = f\"{lon:.3f}\".replace(\".\", \"_\")\n",
    "    base = WEATHER_CACHE_DIR / f\"weather_{safe_lat}_{safe_lon}\"\n",
    "\n",
    "    hourly_file = base.with_suffix(\".hourly.parquet\")\n",
    "    daily_file = base.with_suffix(\".daily.parquet\")\n",
    "\n",
    "    if hourly_file.exists() and daily_file.exists():\n",
    "        console.print(f\"[green]Using cached weather for ({lat}, {lon})[/green]\")\n",
    "        return (\n",
    "            pd.read_parquet(hourly_file),\n",
    "            pd.read_parquet(daily_file)\n",
    "        )\n",
    "\n",
    "    hourly_df, daily_df = fetch_weather_for_location(lat, lon)\n",
    "\n",
    "    hourly_df.to_parquet(hourly_file, index=False)\n",
    "    daily_df.to_parquet(daily_file, index=False)\n",
    "\n",
    "    console.print(f\"[green]Cached weather for ({lat}, {lon})[/green]\")\n",
    "\n",
    "    return hourly_df, daily_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_for_all_event_locations(event_df: pd.DataFrame) -> Dict[tuple, dict]:\n",
    "    \"\"\"\n",
    "    Fetches or loads cached weather for all unique venue coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    locations = get_unique_locations(event_df)\n",
    "\n",
    "    console.print(\n",
    "        Panel(\n",
    "            f\"[cyan]Fetching Weather for {len(locations)} Unique Venue Locations[/cyan]\",\n",
    "            border_style=\"cyan\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    weather_map = {}\n",
    "\n",
    "    for lat, lon in locations:\n",
    "        hourly, daily = load_or_fetch_weather(lat, lon)\n",
    "        weather_map[(lat, lon)] = {\"hourly\": hourly, \"daily\": daily}\n",
    "\n",
    "    return weather_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3580b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_event_weather(event_df: pd.DataFrame, weather_map: Dict[tuple, dict]) -> pd.DataFrame:\n",
    "\n",
    "    df = event_df.copy()\n",
    "    df[\"event_date\"] = pd.to_datetime(df[\"event_date\"], errors=\"coerce\")\n",
    "\n",
    "    df_weather = []\n",
    "\n",
    "    # Group events by location to speed up merging\n",
    "    for (lat, lon), group in df.groupby([\"latitude\", \"longitude\"]):\n",
    "\n",
    "        if (lat, lon) not in weather_map:\n",
    "            console.print(f\"[yellow]No weather found for ({lat}, {lon})[/yellow]\")\n",
    "            df_weather.append(group)\n",
    "            continue\n",
    "\n",
    "        hourly_w = weather_map[(lat, lon)][\"hourly\"].copy()\n",
    "        daily_w = weather_map[(lat, lon)][\"daily\"].copy()\n",
    "\n",
    "        hourly_w[\"weather_hour\"] = pd.to_datetime(hourly_w[\"datetime\"])\n",
    "        daily_w[\"weather_date\"] = pd.to_datetime(daily_w[\"date\"]).dt.date\n",
    "\n",
    "        temp = group.copy()\n",
    "\n",
    "        # HOURLY MERGE\n",
    "        temp[\"event_hour\"] = temp[\"event_date\"].dt.floor(\"h\")\n",
    "        temp = temp.merge(hourly_w.drop(columns=[\"datetime\"]), left_on=\"event_hour\", right_on=\"weather_hour\", how=\"left\")\n",
    "\n",
    "        # DAILY MERGE\n",
    "        temp[\"event_day\"] = temp[\"event_date\"].dt.date\n",
    "        temp = temp.merge(daily_w.drop(columns=[\"date\"]), left_on=\"event_day\", right_on=\"weather_date\", how=\"left\")\n",
    "\n",
    "        df_weather.append(temp)\n",
    "\n",
    "    merged = pd.concat(df_weather, ignore_index=True)\n",
    "\n",
    "    # Clean helper columns\n",
    "    merged.drop(columns=[\"event_hour\", \"weather_hour\", \"event_day\", \"weather_date\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    console.print(\"[green]Weather successfully merged into event data![/green]\")\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"temp_f\" not in df.columns:\n",
    "        console.print(\"[yellow]No temp_f column found — skipping flags.[/yellow]\")\n",
    "        return df\n",
    "\n",
    "    p85 = df[\"temp_f\"].dropna().quantile(0.85)\n",
    "    p15 = df[\"temp_f\"].dropna().quantile(0.15)\n",
    "\n",
    "    df[\"is_hot\"] = (df[\"temp_f\"] >= p85).astype(int)\n",
    "    df[\"is_cold\"] = (df[\"temp_f\"] <= p15).astype(int)\n",
    "    df[\"is_raining\"] = (df.get(\"precip_in\", 0) > 0.01).astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weather_event_panel(event_json_path: str, out_path: str):\n",
    "    console.print(Panel(\"[bold cyan]Building Weather-Enriched Event Panel[/bold cyan]\"))\n",
    "\n",
    "    df_events = pd.read_json(event_json_path)\n",
    "\n",
    "    # Ensure numeric coords\n",
    "    df_events[\"latitude\"] = pd.to_numeric(df_events[\"latitude\"], errors=\"coerce\")\n",
    "    df_events[\"longitude\"] = pd.to_numeric(df_events[\"longitude\"], errors=\"coerce\")\n",
    "\n",
    "    console.print(f\"[blue]Loaded {len(df_events):,} events[/blue]\")\n",
    "\n",
    "    # Fetch + cache weather\n",
    "    weather_map = fetch_weather_for_all_event_locations(df_events)\n",
    "\n",
    "    # Merge weather into events\n",
    "    enriched = merge_event_weather(df_events, weather_map)\n",
    "\n",
    "    # Add flags\n",
    "    enriched = add_weather_flags(enriched)\n",
    "\n",
    "    # Save\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    enriched.to_parquet(out_path, index=False)\n",
    "\n",
    "    console.print(f\"[green]Saved enriched panel → {out_path}[/green]\")\n",
    "\n",
    "    return enriched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df = build_weather_event_panel(\n",
    "    event_json_path=\"data/raw/ticketmaster_us_music_latest.json\",\n",
    "    out_path=\"data/processed/event_weather_panel.parquet\",\n",
    ")\n",
    "\n",
    "enriched_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
